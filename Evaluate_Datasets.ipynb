{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     22,
     25,
     29
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Please set the path to the weka.jar\n",
    "weka_path=\"/usr/weka/weka-3-8-2/weka.jar\"\n",
    "\n",
    "\n",
    "# Imports\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 50)\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "import itertools\n",
    "from copy import deepcopy\n",
    "import time\n",
    "from utils import *\n",
    "\n",
    "### init\n",
    "# Get dictionaries of the data.\n",
    "train_files=!ls DATA/GENERATED|grep -v \"for_DPWGAN\"|grep arff\n",
    "data_train={\n",
    "    \"KCCR\":  [\"DATA/GENERATED/\"+x for x in train_files if \"KCCR\"  in x],\n",
    "    \"KCCFD\": [\"DATA/GENERATED/\"+x for x in train_files if \"KCCFD\" in x],\n",
    "    \"MNIST\": [\"DATA/GENERATED/\"+x for x in train_files if \"MNIST\" in x],}\n",
    "data_eval={\n",
    "    \"MNIST\": \"DATA/PREPROCESSED/TEST/MNIST_TEST.arff\",\n",
    "    \"KCCFD\": \"DATA/PREPROCESSED/TEST/KCCFD_TEST.arff\",\n",
    "    \"KCCR\":  \"DATA/PREPROCESSED/TEST/KCCR_TEST.arff\",}\n",
    "\n",
    "# Define weka models \n",
    "models={\n",
    "    \"J48\":'weka.classifiers.trees.J48 -- -C 0.25 -M 2',\n",
    "    \"NaiveBayes\":'weka.classifiers.bayes.NaiveBayes',\n",
    "    \"RandomForest1\":'weka.classifiers.trees.RandomForest -- -P 100 -I 500 -num-slots 1 -K 5 -M 1.0 -V 0.001 -S 1 -depth 5',\n",
    "    \"RandomForest2\":'weka.classifiers.trees.RandomForest -- -P 100 -I 2000 -num-slots 1 -K 1 -M 1.0 -V 0.001 -S 1 -depth 1',\n",
    "    \"SGD\":'weka.classifiers.functions.SGD -- -F 0 -L 0.01 -R 1.0E-4 -E 500 -C 0.001 -S 1',\n",
    "    \"SMO\":'weka.classifiers.functions.SMO -- -C 1.0 -L 0.001 -P 1.0E-12 -N 0 -V -1 -W 1 -K \"weka.classifiers.functions.supportVector.PolyKernel -E 1.0 -C 250007\" -calibrator \"weka.classifiers.functions.Logistic -R 1.0E-8 -M -1 -num-decimal-places 4\"',\n",
    "    \"SimpleLogistic\":'weka.classifiers.functions.SimpleLogistic -- -I 0 -M 500 -H 50 -W 0.0',\n",
    "    \"IBk\":'weka.classifiers.lazy.IBk -- -K 1 -W 0 -A \\\"weka.core.neighboursearch.LinearNNSearch -A \\\\\\\"weka.core.EuclideanDistance -R first-last\\\\\\\"\\\"',\n",
    "    }\n",
    "\n",
    "\n",
    "# Main functions\n",
    "def generate_run_lists():\n",
    "    # Creates a list of elements with the following form:\n",
    "    #     [Dataset_name,Train_File,Test_File,Model_ID,Boosted(bool),AUROC]\n",
    "    run_lists=[]\n",
    "    for boosted in [False,True]:\n",
    "        for dataset,train_files in data_train.items():\n",
    "            for train in train_files:\n",
    "                test  = data_eval[dataset]\n",
    "                for model_id,_ in models.items():\n",
    "                    run_lists += [[dataset,train,test,model_id,boosted,None]]\n",
    "    return run_lists\n",
    "\n",
    "\n",
    "def parse_weka_model(model_id=None,train=None,val=None,boost=False):\n",
    "    # Parses a Weka command to be run with bash (technically Jupyter uses dash).\n",
    "    global models\n",
    "    string=\"java -classpath \"+weka_path+\" {} -t {} -T {} -o {} -W {}\"\n",
    "    if boost:\n",
    "        # Gradient boosting method in weka.\n",
    "        boost=\"weka.classifiers.meta.AdaBoostM1 -P 100 -S 1 -I 10\"\n",
    "        string = string.format(boost,\"{0}\",\"{1}\",\"\",\"{2}\")\n",
    "    else:\n",
    "        # This filter effectively does nothing.\n",
    "        # Used to avoid messing with escape characters during runtime.\n",
    "        _fc=\"weka.classifiers.meta.FilteredClassifier\"\n",
    "        _f=\"-F weka.filters.unsupervised.attribute.ReplaceMissingValues\"\n",
    "        string = string.format(_fc,\"{0}\",\"{1}\",_f,\"{2}\")\n",
    "    string=string.format(train,val,models[model_id])\n",
    "    return string\n",
    "\n",
    "\n",
    "def get_AUROC(output):\n",
    "    # Retrieves AUROC from the output string. \n",
    "    # It is located directly below the \"ROC Area\" string.\n",
    "    output=output[int(len(output)/2):] # First half of output is evaluation on training data\n",
    "    try:\n",
    "        loc=[j for j,x in enumerate(output) if \"ROC Area\" in x][-1]\n",
    "        _i=output[loc].find(\"ROC Area\")\n",
    "        return float(output[loc+1][_i:_i+8].strip())\n",
    "    except:\n",
    "        print(\"\\n\".join(output))\n",
    "        return None\n",
    "    \n",
    "    \n",
    "def run_models(run_lists):\n",
    "    global new_run_lists\n",
    "    new_run_lists=[]\n",
    "    for run_list in run_lists:\n",
    "        if run_list[5] is None:\n",
    "            train=run_list[1]\n",
    "            t1=time.time() \n",
    "            command = parse_weka_model(model_id=run_list[3],train=train,val=run_list[2],boost=run_list[4])\n",
    "            output =! {command}\n",
    "            performance = get_AUROC(output)\n",
    "            run_list[5] = performance\n",
    "            new_run_lists += [run_list]\n",
    "            print(new_run_lists[-1])\n",
    "            print(\"Time taken:\",time.time()-t1)\n",
    "        else:\n",
    "            new_run_lists += run_list\n",
    "    return new_run_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runlists = generate_run_lists()\n",
    "\n",
    "# # Edit as desired. For example:\n",
    "# runlists=lists_with(runlists,\"MNIST\")\n",
    "# runlists=lists_without(runlists,\"SGD\")\n",
    "\n",
    "print_list(runlists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: because of the try catch statement, the best way to abort is to restart the kernel.\n",
    "results = run_models(runlists)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
